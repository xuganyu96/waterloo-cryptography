\documentclass{article}
\usepackage[margin=1in,letterpaper]{geometry}
\usepackage{amsmath,amsfonts,amssymb,amsthm}

% For source code
\usepackage{listings}

% Algorithms and pseudocode
% \usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{algorithm}
\usepackage{algpseudocode}

% Custom commands
\usepackage{mystyle}

% Environments: definitions, theorems, propositions, corollaries, lemmas
%    Theorems, propositions, and definitions are numbered within the section
%    Corollaries are numbered within the theorem, though they are rarely used
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem*{remark}{Remark}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[theorem]


\title{
    A survey of generic IND-CCA2 transformations
}
\author{
    Ganyu Xu
}
% Leave the date field empty to display the date of compilation
% \date{}

\begin{document}
%%%% TITLE %%%%%
\maketitle

\section{Preliminaries}
\subsection{Public-key encryption schemes}
A public key encryption scheme $\pke = (\keygen, \encrypt, \decrypt)$ is a collection of three routines. $\keygen(1^\lambda)$ takes the security parameteras input and returns a keypair $(\pk, \sk)$. $\encrypt(\pk, m)$ takes some public key and some plaintext message $m \in \mathcal{M}_\pke$ and output a ciphertext $c \in \mathcal{C}_\pke$. Where the encryption routine is probabilistic, we model the randomness using a coin $r \in \mathcal{R}$ such that $E(\pk, m; r)$ is deterministic with an explicit $r$. Finally, $\decrypt(\sk, c)$ uses the secret key to decrypt the ciphertext.

\subsubsection{Correctness}
Conventionally we require a $\pke$ to be perfectly correct. This means that for all possible key pairs $(\pk, \sk)$ and plaintexts $m$, the decryption routine always correctly inverts the encryption routine: $\decrypt(\sk, \encrypt(\pk, m)) = m$.

Where perfect correctness is not achieved, such as with most lattice-based encryption schemes, we need to account for the possiblity that decryption can fail. If under some keypair $(\pk, \sk)$, a plaintext-ciphertext pair $(m, c)$ is such that $c \leftsample \encrypt(\pk, m)$ is obtained from encrypting $m$ (probabilistically) but $m \neq \decrypt(\sk, c)$, we call it a decryption failure. For probabilistic encryption routines where the coin is uniformly sampled from the coin space, we can quantify the probability that $m$ triggers a decryption failure. From here, we can take the distribution of all keypairs and quantify the ``correctness'' of a (possibly imperfectly correct) encryption scheme. The following definition of $\delta$-correctness is directly taken from \cite{bos2018crystals}.

\begin{definition}[$\delta$-correctness]\label{def:delta-correctness-pke}
    A probabilistic public-key encryption scheme $\pke = (\keygen, \encrypt, \decrypt)$ is $\delta$-correct if the expected maximal probability of decryption failure taken across the distribution of keypairs is at most $\delta$:

    \begin{equation*}
        E\left\lbrack\max_{m \in \mathcal{M}} P\left\lbrack
            \decrypt(\sk, \encrypt(\pk, m))
        \right\rbrack
        \right\rbrack \leq \delta
    \end{equation*}

    where the expectation is taken over the distribution of keypairs and the probability is taken over the distribution of coins.
\end{definition}

\cite{hofheinz2017modular} also defined an adversarial game in which the adversary's goal is to find some plaintext message to trigger a decryption failure. This adversarial game meaningfully models the real-world scenario in which decryption failure can reveal information about the secret key. Notice that when evaluating the win condition, the coin is uniformly random instead of being chosen by the adversary.

\begin{figure}[H]
    \center

    \begin{minipage}{0.5\textwidth}
        \begin{algorithm}[H]
            \caption{\monospace{CORS}}
            \begin{algorithmic}[1]
                \State $(\pk, \sk) \leftsample \keygen(1^\lambda)$
                \State $m \leftsample A_\monospace{CORS}(1^\lambda, \pk, \sk)$
                \State \Return $\llbrack \decrypt(\sk, \encrypt(\pk, m)) \neq m \rrbrack$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    
    \caption{The correctness game \monospace{CORS}}\label{fig:cors-game}
\end{figure}

The definition of $\delta$-correctness sets an explicit upper bound on the probability that any plaintext triggers decryption failure. This means that even if the \monospace{CORS} adversary actually finds the message $m$ that is the most likely to trigger decryption failure, the probability of winning the \monospace{CORS} game is still upper-bounded by $\delta$.

\begin{lemma}
    If $\pke$ is $\delta$-correct, then for all \monospace{CORS} adversaries $A$, even computationally unbounded ones, the probability of winning the \monospace{CORS} game is at most $\delta$
\end{lemma}

The values of $\delta$ for Kyber are taken directly from \cite{avanzi2019crystals}

\begin{table}[H]
    \center
    \begin{tabular}{c|c}
        security level & $\delta$ \\
        \hline
        Kyber512 & $2^{-139}$ \\
        \hline
        Kyber768 & $2^{-164}$ \\
        \hline
        Kyber1024 & $2^{-174}$ \\
    \end{tabular}
    \caption{Concrete $\delta$ for Kyber}\label{tbl:kyber-delta-vals}
\end{table}

\subsubsection{Security}
An one-way adversary $A = (A_1, A_2)$ consists of two sub-routines $A_1$ and $A_2$. $s \leftsample A_1^{\mathcal{O}_1}(1^\lambda, \pk)$ takes the security parameter, some public-key, access to some oracle(s) $\mathcal{O}_1$, and outputs some intermediate state $s$. $\hat{m} \leftarrow A_2^{\mathcal{O}_2}(1^\lambda, \pk, c^\ast)$ resumes from the output of $A_1$ and takes some challenge ciphertext, then tries to guess the corresponding decryption.

The advantage $\monospace{Adv}_\monospace{OW-ATK}(A)$ of an \monospace{OW-ATK} adversary is the probability that its guess is correct.

\begin{definition}
    A $\pke$ is \monospace{OW-ATK} secure if for all efficient adversaries $A$, the advantage in the \monospace{OW-ATK} game is neligigble with respect to the security parameter:

    \begin{equation*}
        \monospace{Adv}_\monospace{OW-ATK}(A) \leq \operatorname{negl}(\lambda)
    \end{equation*}
\end{definition}

An \textbf{indistinguishability} adversary $A = (A_1, A_2)$ similarly consists of two sub-routines. The first sub-routine adversarially chooses two distinct plaintext messages, and the second sub-routine tries to distinguish which of the two plaintext messages is the decryptino of the challenge encryption. The advantage of an indistinguishability adversary is defined by $\monospace{Adv}_\monospace{IND-ATK}(A) = P[\hat{b} = b] - \frac{1}{2}$

\begin{definition}
    A $\pke$ is \monospace{IND-ATK} secure if for all efficient adversaries $A$, the advantage in the indistinguishability game is negligible with respect to the security parameter

    \begin{equation*}
        \monospace{Adv}_\monospace{IND-ATK}(A) \leq \operatorname{negl}(\lambda)
    \end{equation*}
\end{definition}

The security games are described in details in figure \ref{fig:sec-games}

\begin{figure}[H]
    \center
    \begin{minipage}{0.49\textwidth}
        \begin{algorithm}[H]
            \caption{\monospace{OW-ATK} game}\label{alg:ow-atk-game}
            \begin{algorithmic}[1]
                \State $(\pk, \sk) \leftsample \keygen(1^\lambda)$
                \State $s \leftsample A_1^{\mathcal{O}_1}(1^\lambda, \pk)$
                \State $m^\ast \leftsample \mathcal{M}$
                \State $c^\ast \leftsample \encrypt(\pk, m^\ast)$
                \State $\hat{m} \leftarrow A_2^{\mathcal{O}_2}(1^\lambda, \pk, s, c^\ast)$
                \State \Return $\llbrack \hat{m} = m^\ast\rrbrack$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \hfill
    \begin{minipage}{0.5\textwidth}
        \begin{algorithm}[H]
            \caption{\monospace{IND-ATK} game}\label{alg:ind-atk-game}
            \begin{algorithmic}[1]
                \State $(\pk, \sk) \leftsample \keygen(1^\lambda)$
                \State $(m_0, m_1) \leftsample A_1^{\mathcal{O}_1}(1^\lambda, \pk)$
                \State $b \leftsample \{0,1\}$
                \State $c^\ast \leftsample \encrypt(\pk, m_b)$
                \State $\hat{b} \leftarrow A_2^{\mathcal{O}_2}(1^\lambda, \pk, s, c^\ast)$
                \State \Return $\llbrack \hat{b} = b \rrbrack$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \caption{The indistinguishability security game}\label{fig:sec-games}
\end{figure}

The capabilities of the adveraries are modeled using different collections of oracles. In standard security requirements, adversaries with access to no additional oracles can only mount chosen plaintex attacks (CPA), adversaries with access to decryption oracle $\mathcal{O}^\decrypt$ only before the receiving challenge ciphertext can mount non-adaptive chosen ciphertext attacks (CCA1), adversaries with access to decryption oracle both before and after receiving the challenge ciphertext can mount adaptive chosen ciphertext attacks (CCA2).

\cite{hofheinz2017modular} also defined two non-standard oracles and the corresponding attacks. The plaintext checking oracle $\pco(m, c)$ returns $1$ if $m$ is a decryption of $c$ and $0$ otherwise. The ciphertext validation oracle $\cvo(c)$ returns $1$ if $c$ is a valid ciphertext and $0$ otherwise.

\begin{figure}[H]
    \center

    \begin{minipage}{0.49\textwidth}
        \begin{algorithm}[H]
            \caption{$\pco(m, c)$}\label{alg:pco}
            \begin{algorithmic}
                \State \Return $\llbrack \decrypt(\sk, c) = m \rrbrack$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \hfill
    \begin{minipage}{0.49\textwidth}
        \begin{algorithm}[H]
            \caption{$\cvo(c)$}\label{alg:cvo}
            \begin{algorithmic}[1]
                \State \Return $\llbrack \decrypt(\sk, c) \in \mathcal{M} \rrbrack$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}

    \caption{$\pco$ and $\cvo$}\label{fig:pco-and-cvo}
\end{figure}

Here is an overview of the various kinds of attacks and their associated oracles

\begin{table}[H]
    \center
    \begin{tabular}{|c|c|c|}
        \hline
        \monospace{ATK} & $\mathcal{O}_1$ & $\mathcal{O}_2$ \\
        \hline
        \monospace{CPA} & \multicolumn{2}{|c|}{$-$} \\
        \hline
        \monospace{CCA1} & $\mathcal{O}^\decrypt$ & - \\
        \hline
        \monospace{CCA2} & \multicolumn{2}{|c|}{$\mathcal{O}^\decrypt$} \\
        \hline
        \monospace{PCVA} & \multicolumn{2}{|c|}{$\pco, \cvo$} \\
        \hline
        \monospace{PCA} & \multicolumn{2}{|c|}{$\pco$} \\
        \hline
        \monospace{VA} & \multicolumn{2}{|c|}{$\cvo$} \\
        \hline
    \end{tabular}
    \caption{Attacks and associated oracle access}
\end{table}

\cite{hofheinz2017modular} stated a ``well-known'' result that the \monospace{IND-CPA} security of a scheme with a large message space implies \monospace{OW-CPA} security:

\begin{theorem}\label{thm:ind-cpa-implies-ow-cpa}
    For every \monospace{IND-CPA} adversary $B$ against some $\pke$, there exists an \monospace{OW-CPA} adversary $A$ against the same $\pke$ such that:

    \begin{equation*}
        \monospace{Adv}_\monospace{OW-CPA}(A) = \frac{1}{\norm{\mathcal{M}}} + \monospace{Adv}_\monospace{IND-CPA}(B)
    \end{equation*}
\end{theorem}

\subsubsection{Spread and rigidity}
The spread of a public key encryption scheme measures the diffusion the encryption routine's output. The higher the spread, the lower the probability of obtaining any specific ciphertext.

\begin{definition}[$\gamma$-spread]\label{def:gamma-spread}
    For a given keypair $(\pk, \sk)$ and plaintext message $m \in \mathcal{M}$, the \emph{min-entropy} of the encryption routine is:
    
    $$\operatorname{min-entropy}(\pk, m) := -\log_2\left( 
        \max_{c \in \mathcal{C}} P\left\lbrack
            c = \encrypt(\pk, m)
        \right\rbrack
    \right) $$

    A $\pke$ has $\gamma$-spread if for all keypairs $(\pk, \sk)$ and plaintext $m \in \mathcal{M}$:

    $$
        \operatorname{min-entropy}(\pk, m) \leq \gamma
    $$
\end{definition}

Having $\gamma$ sperad means that for any keypair $(\pk, \sk)$, plaintext $m$, and ciphertext $c$:

$$
P\left\lbrack c = \encrypt(\pk, m) \right\rbrack \leq 2^{-\lambda}
$$

Finally, \emph{rigidity} conveys the idea that a ciphertext cannot be perturbed without becoming either invalid or decrypting to another plaintext

\begin{definition}[rigidity]\label{def:rigidity}
    $\pke(\keygen, \encrypt, \decrypt)$ is \emph{rigid} if for all keypairs $(\pk, \sk)$ and ciphertext $c$, either $\decrypt(\sk, c) = \bot$ or $\encrypt\left(\pk, \decrypt(\sk, c)\right) = c$
\end{definition}

\subsection{Key encapsulation mechanism}
A key encapsulation mechanism $\kem = (\keygen, \encap, \decap)$ is a collection of three routines. The key generation routine $(\pk, \sk) \leftsample \keygen(1^\lambda)$ takes the security parameter $1^\lambda$ and returns a keypair. The encapsulation routine $(c, K) \leftsample \encap(\pk)$ takes the public key and outputs some ciphertext $c \in \mathcal{C}_\kem$ and some shared secret $K \in \mathcal{K}_\kem$. Finally, the decapsulation routine $K \leftarrow \decap(\sk, c)$ takes the secret key and a ciphertext and outputs the correponding shared secret.

\emph{Correctness}: similar to a $\pke$, key encapsulation mechanisms are usually required to be perfectly correct, meaning that for all keypairs $(\pk, \sk)$, decapsulation always outputs the same shared secret as the encapsulation

\begin{equation*}
    \Prob{(c, K_1) \leftsample \encap(\pk); K_2 \leftarrow \decap(\sk, c); K_1 = K_2} = 1
\end{equation*}

However, where decapsulation failure has a non-zero probability, we need to upperbound this quantity.

\begin{definition}[$\delta$-correctness]\label{def:delta-correctness-kem}
    A $\kem = (\keygen, \encap, \decap)$ is $\delta$-correct if the probability of decapsulation failure taken across the keypair distribution is at most $\delta$:

    \begin{equation*}
        P\lrbrack{
            \decap(\sk, c) \neq K 
            \mid (\pk, \sk) \leftsample \keygen()
                ; (c, K) \leftsample \encap(\pk)
        } \leq \delta
    \end{equation*}
\end{definition}

\emph{Security}: the security of a $\kem$ is defined in an adversarial game in which the adversary's goal is to distinguish between shared secret derived from encapsulation and uniformly random samples. An adversary $A = (A_1, A_2)$ contains two sub-routines with access to some oracle $\mathcal{O}$ depending on game.

\begin{figure}[H]
    \center
    \begin{minipage}{0.49\textwidth}
        \begin{algorithm}[H]
            \caption{\monospace{IND-CCA2} game}
            \begin{algorithmic}[1]
                \State $(\pk, \sk) \leftsample \keygen(1^\lambda)$
                \State $s \leftsample A_1^{\mathcal{O}^\decap}(1^\lambda, \pk)$
                \State $(c^\ast, K_0) \leftsample \encap(\pk)$
                \State $K_1 \leftsample \mathcal{K}_\kem$
                \State $b \leftsample \{0, 1\}$
                \State $\hat{b} \leftsample A_2^{\mathcal{O}^\decap}(1^\lambda, \pk, s, c^\ast, K_b)$
                \State \Return $\llbrack \hat{b} = b \rrbrack$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \hfill
    \begin{minipage}{0.49\textwidth}
        \begin{algorithm}[H]
            \caption{$\decap$ oracle $\mathcal{O}^\decap(c \neq c^\ast)$}
            \begin{algorithmic}[1]
                \State \Return $\decap(\sk, c)$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \caption{The \monospace{IND-CCA2} game for $\kem$}\label{fig:kem-ind-cca2-game}
\end{figure}

\begin{definition}[\monospace{IND-CCA2 security}]\label{def:kem-ind-cca2-security}
    A $\kem = (\keygen, \encap, \decap)$ is \monospace{IND-CCA2} secure if no efficient adversary has non-negligible advantage in the \monospace{IND-CCA2} game.
\end{definition}

\section{Modular Fujisaki-Okamoto transformation}
The Fujisaki-Okamoto transformation \cite{fujisaki1999secure} and its KEM variations \cite{hofheinz2017modular} achieve security against adaptive chosen-ciphertext attacks through \emph{de-randomization} and \emph{re-encryption}. In particular, the modular FO transformation contains two steps. The first step (denoted the $T$ transformation) takes a $\pke = (\keygen, \encrypt, \decrypt)$ and outputs a $\pke_1 = (\keygen, \encrypt_1, \decrypt_1)$. The key generation remains unchanged, but the encryption routine is \emph{de-randomized} by deriving the coin from the plaintext using a hash function $G: \mathcal{M}_\pke \rightarrow \mathcal{R}_\pke$, and the decryption routine uses \emph{re-encryption} to reject invalid ciphertexts.

\begin{figure}[H]
    \begin{minipage}{0.49\textwidth}
        \begin{algorithm}[H]
            \caption{$\encrypt_1(\pk, m)$}\label{alg:encrypt-1}
            \begin{algorithmic}[1]
                \State $r \leftarrow G(m)$
                \State $c \leftarrow \encrypt(\pk, m; r)$
                \State \Return $c$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \hfill
    \begin{minipage}{0.49\textwidth}
        \begin{algorithm}[H]
            \caption{$\decrypt_1(\sk, c)$}\label{alg:decrypt-1}
            \begin{algorithmic}[1]
                \State $\hat{m} \leftarrow D(\sk, c)$
                \If{
                    $\hat{m} \in \mathcal{M}_\pke 
                    \;\land\; \encrypt(\pk, \hat{m}; G(\hat{m})) = c$
                }
                    \State \Return $\hat{m}$
                \EndIf
                \State \Return $\bot$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}

    \caption{T transformation}\label{fig:t-transformation}
\end{figure}

\cite{hofheinz2017modular} states the security property of $\pke_1$ as follows:

\begin{theorem}\label{thm:owcpa-implies-owpcva}
    If $\pke$ is $\delta$-correct and has $\gamma$ spread, then for every \monospace{OW-PCVA} adversary $B$ against $\pke_1$ who makes $q_G$ hash queries, $q_V$ ciphertext validation queries, and $q_P$ plaintext checking queries, there exists an \monospace{OW-CPA} adversary $A$ such that:

    \begin{equation*}
        \monospace{Adv}(B) \leq q_V \cdot 2^{-\gamma}
            + (q_G + q_P) \cdot \delta
            + (1 + q_G + q_P) \cdot \monospace{Adv}(A)
    \end{equation*}
\end{theorem}

In other words, if $\pke$ is \monospace{OW-CPA} secure, then $\pke_1$ is \monospace{OW-PCVA} secure, though the security is non-tight. On the other hand, if $\pke$ is \monospace{IND-CPA} secure, the \monospace{OW-PCVA} security is tight:

\begin{theorem}\label{thm:indcpa-implies-owpcva}
    for every \monospace{OW-PCVA} adversary $B$ against $\pke_1$ who makes $q_G$ hash queries, $q_V$ ciphertext validation queries, and $q_P$ plaintext checking queries, there exists an \monospace{IND-CPA} adversary $A$ such that:

    \begin{equation*}
        \monospace{Adv}(B) \leq q_V \cdot 2^{-\gamma}
            + (q_G + q_P) \cdot \delta
            + \frac{2 \cdot q_G + 1}{\norm{\mathcal{M}_\pke}}
            + 3 \cdot \monospace{Adv}(A)
    \end{equation*}
\end{theorem}

\begin{proof}
    We will provide a sketch of proof for theorem \ref{thm:owcpa-implies-owpcva} and \ref{thm:indcpa-implies-owpcva}. The main idea is to construct an \monospace{OW-CPA}/\monospace{IND-CPA} adversary $A$ who can simulate the \monospace{OW-PCVA} game and use the \monospace{OW-PCVA} adversary $B$ as a sub-routine. However, there are three main difficulties with constructing a ``convincing'' simulation:

    \begin{enumerate}
        \item $A$ has no access to $\pco$
        \item $A$ has no access to $\cvo$
        \item The challenge ciphertext $A$ receives is obtained using a truly random coin, but the challenge ciphertext $B$ expects is obtained using a pseudorandom coin $r \leftarrow G(m)$
    \end{enumerate}

    % TODO: finish writing this section
\end{proof}

\subsection{From PKE to KEM}
The second part of the modular FO transform (denoted the $U$ transform) takes a $\pke$ and outputs a $\kem$. Depending on whether the input $\pke$ is rigid and whether the output $\kem$ rejects invalid ciphertext implicitly or explicitly, the security requirements for the input $\pke$ and the construction of the $\kem$ will vary. \cite{hofheinz2017modular} presents four variations of the $U$ transform, which are listed in table \ref{tbl:u-transform-summary}

\begin{table}[H]
    \center
    \begin{tabular}{|c|c|c|c|}
        \hline
        Name & $\pke$ requirements & rejection & shared secret\\
        \hline
        $U^\bot$ & \monospace{OW-PCVA} & $\bot$ & $H(m, c)$ \\
        \hline
        $U^{\not\bot}$ & \monospace{OW-PCA} & $H(s, c)$ & $H(m, c)$ \\
        \hline
        $U^\bot_m$ & rigidity + \monospace{OW-VA} & $\bot$ & $H(m)$ \\
        \hline
        $U^{\not\bot}_m$ & rigidity + \monospace{OW-CPA} & $H(s, c)$ & $H(m)$ \\
        \hline
    \end{tabular}
    \caption{A summary of variants of $U$ transformations}\label{tbl:u-transform-summary}
\end{table}

For the remaining of this section we will present the four transformations and sketch proofs of their securities.

\subsubsection{KEM with explicit rejection from randomized PKE}
Let $\pke = (\keygen, \encrypt, \decrypt)$ be a public-key encryption scheme, and $H: \mathcal{M}_\pke \times \mathcal{C}_\pke \rightarrow \mathcal{K}_\kem$ be a hash function. The $U^\bot$ transformation outputs a $\kem^\bot = (\keygen^\bot, \encap^\bot, \decap^\bot)$, where the key generation routine remains unchanged: $\keygen^\bot = \keygen$. The encapsulation and decapsulation routines are described in figure \ref{fig:u-bot-routines}

\begin{figure}[H]
    \begin{minipage}{0.49\textwidth}
        \begin{algorithm}[H]
            \caption{$\encap^\bot(\pk)$}\label{alg:u-bot-encap}
            \begin{algorithmic}[1]
                \State $m \leftsample \mathcal{M}_\pke$
                \State $c \leftsample \encrypt(\pk, m)$
                \State $K \leftarrow H(m, c)$
                \State \Return $(c, K)$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \hfill
    \begin{minipage}{0.49\textwidth}
        \begin{algorithm}[H]
            \caption{$\decap^\bot(\sk, c)$}\label{alg:u-bot-decap}
            \begin{algorithmic}[1]
                \State $\hat{m} \leftarrow \decrypt(\sk, c)$
                \If{$\hat{m} \in \mathcal{M}_\pke$}
                    \State $K \leftarrow H(\hat{m}, c)$
                    \State \Return $K$
                \EndIf
                \State \Return $\bot$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \caption{$U^\bot$ routines}\label{fig:u-bot-routines}
\end{figure}

Under the random oracle model, the security of $\kem^\bot$ depends on the security of the input $\pke$.

\begin{theorem}\label{thm:owpcva-implies-indcca2}
    For every \monospace{IND-CCA2} adversary $B$ against $\kem^\bot$, there exists an \monospace{OW-PCVA} adversary $A$ against the underlying $\pke$ such that

    \begin{equation*}
        \monospace{Adv}(B) \leq \monospace{Adv}(A)
    \end{equation*}
\end{theorem}

\begin{proof}
    For a sketch of proof, we argue that under the random oracle model, $H(m, c)$ is indistinguishable from a uniformly random sample from $\mathcal{K}_\kem$ from the adversary $B$'s perspective unless $B$ somehow queries $H$ on $(m, c)$. This means that an \monospace{OW-PCVA} adversary can perfectly simulate the decapsulation oracle using uniformly random samples, as long as the outputs from the simulated decapsulation oracle are consistent with the outputs from the hash functions.

    The only flaw in the simulated decapsulated oracle lies in the case when $B$ queries $H(m^\ast, c^\ast)$, but because $A$ has access to $\pco$, $A$ can detect that $B$ has successfully recovered $m^\ast$ and uses the recovered $m^\ast$ to win the \monospace{OW-PCVA} game. In other words, $A$ keeps running $B$ in a simulation until $B$ makes the special hash query, at which time $A$ simply terminates $B$ and outputs the answer.

    To make the simulated decapsulation oracle and the hash oracle consistent, $A$ maintains two tapes $\mathcal{L}^\decap$ and $\mathcal{L}^H$ that record the queries made to the decapsulation oracle and the hash oracles respectively: 
    
    $$
    \begin{aligned}
        (c, K) \in \mathcal{L}^\decap &\Leftrightarrow K = \mathcal{O}^\decap(c) \\
        (m, c, K) \in \mathcal{L}^H &\Leftrightarrow K = H(m, c)
    \end{aligned}
    $$

    If $\mathcal{O}^\decap$ has been queried with some valid ciphertext $c$, then when $H$ is queried with a corresponding input $(m, c)$ where $m$ is the decryption of $c$, $H$ needs to output the same value as $\mathcal{O}^\decap$. Similarly, if $H$ has been queried with some valid plaintext-ciphertext pair $(m, c)$, then when $\mathcal{O}^\decap$ is queried with $c$, the two oracles need to output the same value. The details of the simulation are described in figure \ref{fig:u-bot-patched-oracles}

    \begin{figure}[H]
        \begin{minipage}{0.49\textwidth}
            \begin{algorithm}[H]
                \caption{$\mathcal{O}^\decap_1(c)$}\label{alg:u-bot-patched-decap}
                \begin{algorithmic}[1]
                    \If{$\exists (\tilde{c}, \tilde{K}) \in \mathcal{L}^\decap : \tilde{c} = c$}
                        \State \Return $\tilde{K}$
                    \EndIf
                    \If{$\cvo(c) = 1$}
                        \State $K \leftsample \mathcal{K}_\kem$
                        \State Append $(c, K)$ to $\mathcal{L}^\decap$
                        \State \Return $K$
                    \EndIf
                    \State \Return $\bot$
                \end{algorithmic}
            \end{algorithm}
        \end{minipage}
        \hfill
        \begin{minipage}{0.49\textwidth}
            \begin{algorithm}[H]
                \caption{$H_1(m, c)$}\label{alg:u-bot-patched-hash}
                \begin{algorithmic}[1]
                    \If{$\exists (\tilde{m}, \tilde{c}, \tilde{K}) \in \mathcal{L}^H:(\tilde{m}, \tilde{c}) = (m, c)$}
                        \State \Return $\tilde{K}$
                    \EndIf
                    \State $K \leftsample \mathcal{K}_\kem$
                    \If{$\pco(m, c) = 1$}
                        \If{$\exists (\tilde{c}, \tilde{K}) \in \mathcal{L}^\decap : \tilde(c) = c$}
                            \State \Return $\tilde{K}$
                        \Else
                            \State Append $(c, K)$ to $\mathcal{L}^\decap$
                        \EndIf
                    \EndIf
                    \State Append $(m, c, K)$ to $\mathcal{L}^H$
                    \State \Return $K$
                \end{algorithmic}
            \end{algorithm}
        \end{minipage}
        \caption{Patched oracles in $U^\bot$}\label{fig:u-bot-patched-oracles}
    \end{figure}
\end{proof}

\subsubsection{KEM with implicit rejection from randomized PKE}
Given $\pke = (\keygen, \encrypt, \decrypt)$, the $U^{\not\bot}$ transformation outputs $\kem = (\keygen^{\not\bot}, \encap^{\not\bot}, \decap^{\not\bot})$. With implicit rejection, decapsulation routine returns some output from $H$ even when the input ciphertext $c$ is malformed. Specifically, the implicit rejection value depends on the ciphertext and some secret value $s$ that is a part of the secret key.

\begin{figure}[H]
    \center
    \begin{minipage}{0.33\textwidth}
        \begin{algorithm}[H]
            \caption{$\keygen^{\not\bot}$}\label{alg:u-notbot-keygen}
            \begin{algorithmic}[1]
                \State $(\pk, \sk^\prime) \leftsample \keygen(1^\lambda)$
                \State $s \leftsample \mathcal{M}_\pke$
                \State $\sk = (\sk^\prime, s)$
                \State \Return $(\pk, \sk)$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \hfill
    \begin{minipage}{0.33\textwidth}
        \begin{algorithm}[H]
            \caption{$\encap^{\not\bot}(\pk)$}\label{alg:u-notbot-encap}
            \begin{algorithmic}[1]
                \State $m \leftsample \mathcal{M}_\pke$
                \State $c \leftsample \encrypt(\pk, m)$
                \State $K \leftarrow H(m, c)$
                \State \Return $(c, K)$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \hfill
    \begin{minipage}{0.32\textwidth}
        \begin{algorithm}[H]
            \caption{$\decap^{\not\bot}(\sk, c)$}\label{alg:u-notbot-decap}
            \begin{algorithmic}[1]
                \State $\hat{m} \leftarrow \decrypt(\sk, c)$
                \If{$\hat{m} \in \mathcal{M}_\pke$}
                    \State $K \leftarrow H(\hat{m}, c)$
                    \State \Return $K$
                \EndIf
                \State \Return $H(s, c)$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \caption{$U^{\not\bot}$ routines}\label{fig:u-notbot-routines}
\end{figure}

The security of $\kem^{\not\bot}$, similar to the security of $\kem^\bot$, derives from the indistinguishability between pseudorandom $K \leftarrow H(m, c)$ and truly random $K \leftsample \mathcal{K}_\kem$ under the random oracle model, unless the $\kem$ adversary somehow queries $H$ on $(m^\ast, c^\ast)$, in which case an adversary against the underlying $\pke$ with access to a $\pco$ can detect this special query use it to win the \monospace{OW-PCA} game. In addition, because $\decap^{\not\bot}$ will always return random-looking values regardless of the validity of the input ciphertext, the decapsulation oracle can be simulated without needing a ciphertext validation oracle. The $\kem$ adversary will be able to distinguish between a true decapsulation oracle and a simulated decapsulation oracle, but only by querying $H$ on $(s, c)$ for some $c$. Since $s$ is uniformly random, each query has a $\norm{\mathcal{M}_\pke}^{-1}$ chance of hitting $s$, so across $q_H$ hash queries to $H$, the probability of hitting $s$ at least once is at most $\frac{q_H}{\norm{\mathcal{M}_\pke}}$.

\begin{theorem}
    For every \monospace{IND-CCA} adversary $B$ against $\kem^{\not\bot}$ that makes $q_H$ hash queries to $H$, there exists an \monospace{OW-PCA} adversary $A$ against the underyling $\pke$ such that:

    \begin{equation*}
        \monospace{Adv}(B) \leq \frac{q_H}{\norm{\mathcal{M}_\pke}} + \monospace{Adv}(A)
    \end{equation*}
\end{theorem}

\subsubsection{KEM with explicit rejection from rigid PKE}
If the input $\pke$ is rigid (definition \ref{def:rigidity}), then the $\pco$ can be simulated with indistinguishability from the true $\pco$ except for when decryption failure occurs. Given $\pke = (\keygen, \encrypt, \decrypt)$ and hash function $H: \mathcal{M}_\pke \rightarrow \mathcal{K}_\kem$, the $U^\bot_m$ transformation outputs a $\kem^\bot_m = (\keygen, \encap^\bot_m, \decap^\bot_m)$ where the key generation routine remains unchanged. The encapsulation and decapsulation routines are described in figure \ref{fig:u-bot-m-routines}

\begin{figure}[H]
    \center
    \begin{minipage}{0.49\textwidth}
        \begin{algorithm}[H]
            \caption{$\encap^\bot_m(\pk)$}\label{alg:encap-bot-m}
            \begin{algorithmic}[1]
                \State $m \leftsample \mathcal{M}_\pke$
                \State $c \leftarrow \encrypt(\pk, m)$
                \State $K \leftarrow H(m)$
                \State \Return $(c, K)$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \hfill
    \begin{minipage}{0.49\textwidth}
        \begin{algorithm}[H]
            \caption{$\decap^\bot_m(\sk, c)$}\label{alg:decap-bot-m}
            \begin{algorithmic}[1]
                \State $\hat{m} \leftarrow \decrypt(\sk, c)$
                \If{$\hat{m} \in \mathcal{M}_\pke$}
                    \State \Return $H(m)$
                \EndIf
                \State \Return $\bot$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \caption{$\kem^\bot_m$ routines}\label{fig:u-bot-m-routines}
\end{figure}

Under the random oracle model, no adversary $B$ can distinguish between the pseudorandom $K_0 \leftarrow H(m)$ and the truly random $K_1 \leftsample \mathcal{K}_\kem$ unless $B$ queries $H$ on $m^\ast$.  Because rigidity means $\encrypt(\pk, m^\ast) = c^\ast$ is equivalent to $\decrypt(\sk, c^\ast) = m^\ast$, if $H$ is queried on $m^\ast$, a second adversary $A$ against the $\pke$ can detect the special query and use it to win the \monospace{OW-VA} game.

\begin{theorem}
    For every \monospace{IND-CCA2} adversary $B$ against $\kem^\bot_m$, there exists an \monospace{OW-VA} adversary $A$ against the underlying $\pke$ such that

    \begin{equation*}
        \monospace{Adv}(B) \leq \monospace{Adv}(A) + \delta \cdot (q_H + q_D)
    \end{equation*}
\end{theorem}

\subsubsection{KEM with implicit rejection from rigid PKE}
\begin{figure}[H]
    \caption{$U^{\not\bot}_m$ routines}\label{fig:u-notbot-m-routines}
\end{figure}
% TODO: write out this section

\subsection{Applications}
Kyber's round 3 submission \cite{avanzi2019crystals} and ML-KEM \cite{key2023mechanism} uses \emph{de-randomization}, \emph{re-encryption}, and some variation of the $U$ transformation to convert the \monospace{IND-CPA} $\pke$ into an \monospace{IND-CCA2} $\kem$. Here we recall the \monospace{IND-CPA} $\pke$ first, then describe and discuss their respective KEM construction.

In the $\pke$, $R_q = \mathbb{Z}_q[x]/\langle x^n + 1 \rangle$ denotes the quotient ring, $\mathcal{X}_\eta$ denotes the centered binomial distribution that spans $\{-\eta, \eta+1, \ldots, \eta-1, \eta\}$. The plaintext space is the set of all polynomials in $R_q$ with coefficients $0, 1$. $k$ denotes the dimensions of the secret. The full set of parameters is listed in table \ref{tbl:kyber-params}

\begin{table}[H]
    \center
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        Security level & n & q & k & $\eta_1$ & $\eta_2$ \\
        \hline
        Kyber512 & 256 & 3329 & 2 & 3 & 2 \\
        \hline
        Kyber768 & 256 & 3329 & 3 & 2 & 2 \\
        \hline
        Kyber1024 & 256 & 3329 & 4 & 3 & 2 \\
        \hline
    \end{tabular}
    \caption{Kyber/ML-KEM parameter set}\label{tbl:kyber-params}
\end{table}

The \monospace{IND-CPA} $\pke(\keygen, \encrypt, \decrypt)$ is identical between round 3 Kyber and ML-KEM. The details of the $\pke$ routines are described in figure \ref{fig:kyber-pke-routines}

\begin{figure}[H]
    \begin{minipage}{0.3\textwidth}
        \begin{algorithm}[H]
            \caption{$\keygen_\pke$}\label{alg:kyber-pke-keygen}
            \begin{algorithmic}[1]
                \State $A \leftsample R_q^{k \times k}
                    , \mathbf{s} \leftsample \mathcal{X}_{\eta_1}^k$
                \State $\mathbf{t} \leftarrow A \cdot \mathbf{s}$
                \State $\pk \leftarrow (A, \mathbf{t}), \sk \leftarrow \mathbf{s}$
                \State \Return $(\pk, \sk)$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \hfill
    \begin{minipage}{0.3\textwidth}
        \begin{algorithm}[H]
            \caption{$\encrypt_\pke(\pk, m)$}\label{alg:kyber-pke-encrypt}
            \begin{algorithmic}[1]
                \State $(A, \mathbf{t}) \leftarrow \pk$
                \State $\mathbf{r}_1 \leftsample \mathcal{X}_{\eta_1}^k$
                \State $\mathbf{e}_1 \leftsample \mathcal{X}_{\eta_2}^k,
                    e_2 \leftsample \mathcal{X}_{\eta_2}$
                \State $\mathbf{c}_1 \leftarrow A^\intercal \cdot \mathbf{r}_1 + \mathbf{e}_1$
                \State $c_2 \leftarrow \mathbf{t}^\intercal \cdot \mathbf{r}_1 + e_2 + m \cdot \round{\frac{q}{2}}$
                \State \Return $(\mathbf{c}_1, c_2)$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \hfill
    \begin{minipage}{0.3\textwidth}
        \begin{algorithm}[H]
            \caption{$\decrypt_\pke(\sk, c)$}\label{alg:kyber-pke-decrypt}
            \begin{algorithmic}[1]
                \State $(\mathbf{c}_1, c_2) \leftarrow c$
                \State $\mathbf{s} \leftarrow \sk$
                \State $\hat{m} = c_2 - \mathbf{s}^\intercal \cdot \mathbf{c}_1$
                \State $\hat{m} \leftarrow \operatorname{Round}(\hat{m})$
                \State \Return $\hat{m}$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \caption{$\pke$ routines}\label{fig:kyber-pke-routines}
\end{figure}

For constructing $\kem$ from $\pke$, Kyber uses the $U^{\not\bot}$ transformation while ML-KEM uses the $U^{\not\bot}_m$ transformation. In implementation, however, there are two deviations from algorithm listed in figure \ref{fig:u-notbot-routines} and \ref{fig:u-notbot-m-routines}.

The first deviation is the inclusion of the public key $\pk$ when deriving the coin. Instead of deriving coin from the plaintext only $r \leftarrow G(m)$, Kyber and ML-KEM derive the coin from both the plaintext and (a hash of) the public key $(K, r) \leftarrow G(m, H(\pk))$. The main rationale \cite{bos2018crystals} behind this design choice is to prevent adversaries from precomputing $m$ values that have a high likelihood of triggering decryption failure, which can reveal information about the secret key.

Recall from the decryption routine $\decrypt_\pke$:

\begin{equation*}
    \begin{aligned}
        \hat{m} &= \mathbf{s}^\intercal \cdot \mathbf{c}_1 - c_2 \\
        &= \mathbf{s}^\intercal \cdot (
            A^\intercal \cdot \mathbf{r}_1 + \mathbf{e}_1
        ) - (
            \mathbf{t}^\intercal \cdot \mathbf{r}_1 + e_2 
            + m \cdot \round{\frac{q}{2}}
        ) \\
        &= \mathbf{s}^\intercal \cdot (
            A^\intercal \cdot \mathbf{r}_1 + \mathbf{e}_1
        ) - (
            (
                A\cdot\mathbf{s} + \mathbf{e}
            )^\intercal \cdot \mathbf{r}_1 + e_2 
            + m \cdot \round{\frac{q}{2}}
        ) \\
        &= \mathbf{s}^\intercal \cdot \mathbf{e}_1 
            - \mathbf{e}^\intercal \cdot \mathbf{r}_1 
            + e_2 + m \round{\frac{q}{2}}
    \end{aligned}
\end{equation*}

A decryption failure occurs if the noise term $\mathbf{s}^\intercal\cdot\mathbf{e}_1 - \mathbf{e}^\intercal\cdot\mathbf{r}_1 + e_2$ has large coefficient, which roughly translates to $\mathbf{s}^\intercal\cdot\mathbf{e}_1$ having large coefficients. If the coin $r \leftarrow G(m)$ is entirely derived from the adversary, then the adversary can compute a large number of $\mathbf{r}_1, \mathbf{e}_1, e_2$ offline, then observe which set of $\mathbf{r}_1, \mathbf{e}_1, e_2$ trigger decryption failure, which then can be used to infer information about $\mathbf{s}$ and $\mathbf{e}$. On the other hand, if the coin is derived from both the message and the public key, then the adversary needs to compute a large set of value per keypair, which pushes this attack into infeasibility even for adversaries with large quantum computers.

A second deviation is that instead of deriving the shared secret from the plaintext and the ciphertext $K \leftarrow H(m, c)$, Kyber derives the shared secret from the plaintext and \emph{a hash of the ciphertext}. Since ML-KEM uses the $U^{\not\bot}_m$ transformation, this deviation does not apply. \cite{bos2018crystals} cites benchmarking for non-incremental hash APIs to be the reason for this deviation, which I do not fully understand, but has likely less to do with the security of the scheme and more with verification and compliance.

The details of Kyber and ML-KEM's KEM construction are described in figures \ref{fig:kyber-kem-routines} and \ref{fig:mlkem-kem-routines} respectively.

\begin{figure}[H]
    \begin{minipage}{0.3\textwidth}
        \begin{algorithm}[H]
            \caption{$\keygen_\monospace{KyberKEM}$}\label{alg:kyber-kem-keygen}
            \begin{algorithmic}[1]
                \State $(\pk_\pke, \sk_\pke) \leftsample \keygen_\pke()$
                \State $z \leftsample R_{0,1}$
                \State $h \leftarrow H(\pk_\pke)$
                \State $\sk_\kem \leftarrow (\sk_\pke, z, h, \pk_\pke)$
                \State $\pk_\kem \leftarrow \pk_\pke$
                \State \Return $(\pk_\kem, \sk_\kem)$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \hfill
    \begin{minipage}{0.33\textwidth}
        \begin{algorithm}[H]
            \caption{$\encap_\monospace{KyberKEM}(\pk)$}\label{alg:kyber-kem-encap}
            \begin{algorithmic}[1]
                \State $m \leftsample R_2$
                \State $(K, r) \leftarrow G(H(\pk), m)$
                \State $c \leftarrow \encrypt_\pke(\pk, m; r)$
                \State $K \leftarrow \monospace{KDF}(K, c)$
                \State \Return $(c, K)$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \hfill
    \begin{minipage}{0.33\textwidth}
        \begin{algorithm}[H]
            \caption{$\decap_\monospace{KyberKEM}(\sk, c)$}\label{alg:kyber-kem-decap}
            \begin{algorithmic}[1]
                \State $(\sk_\pke, z, h, \pk_\pke) \leftarrow \sk$
                \State $\hat{m} \leftarrow \decrypt_\pke(\sk_\pke, c)$
                \State $(\hat{K}, \hat{r}) \leftarrow G(h, \hat{m})$
                \State $\hat{c} \leftarrow \encrypt_\pke(\pk, \hat{m}; \hat{r})$
                \If{$\hat{c} = c$}
                    \State \Return $\monospace{KDF}(\hat{K}, H(\hat{c}))$
                \Else
                    \State \Return $\monospace{KDF}(z, H(\hat{c}))$
                \EndIf
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \caption{Kyber's KEM routines}\label{fig:kyber-kem-routines}
\end{figure}

\begin{figure}[H]
    \begin{minipage}{0.3\textwidth}
        \begin{algorithm}[H]
            \caption{$\keygen_\monospace{ML-KEM}$}\label{alg:mlkem-keygen}
            \begin{algorithmic}[1]
                \State $(\pk_\pke, \sk_\pke) \leftsample \keygen_\pke()$
                \State $z \leftsample R_2$
                \State $h \leftarrow H(\pke_\pke)$
                \State $\sk_\kem \leftarrow (\sk_\pke, z, h, \pk_\pke)$
                \State $\pk_\kem \leftarrow \pke_\pke$
                \State \Return $(\pk_\kem, \sk_\kem)$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \hfill
    \begin{minipage}{0.33\textwidth}
        \begin{algorithm}[H]
            \caption{$\encap_\monospace{ML-KEM}(\pk_\kem)$}\label{alg:mlkem-encap}
            \begin{algorithmic}[1]
                \State $m \leftsample R_2$
                \State $(K, r) \leftarrow G(m, H(\pk))$
                \State $c \leftarrow \encrypt_\pke(\pk, m; r)$
                \State \Return $(c, K)$
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \hfill
    \begin{minipage}{0.33\textwidth}
        \begin{algorithm}[H]
            \caption{$\decap_\monospace{ML-KEM}(\sk, c)$}\label{alg:mlkem-decap}
            \begin{algorithmic}[1]
                \State $(\sk_\pke, z, h, \pk_\pke) \leftarrow \sk$
                \State $\hat{m} \leftarrow \decrypt_\pke(\sk_\pke, c)$
                \State $(\hat{K}, \hat{r}) \leftarrow G(\hat{m}, h)$
                \State $K^\prime \leftarrow \monospace{KDF}(z, c)$
                \State $\hat{c} \leftarrow \encrypt_\pke(\pk_\pke, \hat{m}; \hat{r})$
                \If{$\hat{c} = c$}
                    \State \Return $\hat{K}$
                \Else
                    \State \Return $K^\prime$
                \EndIf
            \end{algorithmic}
        \end{algorithm}
    \end{minipage}
    \caption{ML-KEM's KEM routines}\label{fig:mlkem-kem-routines}
\end{figure}

\bibliographystyle{alpha}
\bibliography{./references.bib}

\end{document}